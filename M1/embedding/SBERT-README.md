# SBERT - Sentence Embeddings (Zadanie 4.3)

## ğŸ“‹ PrzeglÄ…d

Implementacja zadania 4.3 - wykorzystanie pretrenowanego modelu Sentence-BERT do generowania embeddingÃ³w zdaÅ„ i wyszukiwania semantycznego.

**Rozdzielenie na dwa etapy:**
1. **Kodowanie bazy danych** (`sbert-encode-database.py`) - jednorazowe
2. **Odpytywanie bazy** (`sbert-query-database.py`) - wielokrotne

## ğŸš€ Szybki start

### Krok 1: Zakoduj bazÄ™ danych (raz)

```bash
# DomyÅ›lnie - korpus ALL
python sbert-encode-database.py

# Lub wybierz konkretny korpus
python sbert-encode-database.py --corpus WOLNELEKTURY
python sbert-encode-database.py --corpus PAN_TADEUSZ
```

**Czas wykonania:**
- WOLNELEKTURY: ~2-5 minut
- ALL: ~5-15 minut (zaleÅ¼nie od CPU/GPU)

**Pliki wyjÅ›ciowe:**
- `sbert_sentence_embeddings.npy` - macierz embeddingÃ³w
- `sbert_sentence_map.json` - mapowanie ID â†’ zdanie
- `sbert_database_stats.json` - statystyki

### Krok 2: Odpytuj bazÄ™ (wielokrotnie)

```bash
# Wszystkie testy (wymyÅ›lone + z korpusu)
python sbert-query-database.py

# Tylko test wymyÅ›lonych zdaÅ„
python sbert-query-database.py --test-invented

# Tylko test zdaÅ„ z korpusu
python sbert-query-database.py --test-corpus

# Pojedyncze zapytanie
python sbert-query-database.py --query "KrÃ³l wydaÅ‚ rozkaz swoim rycerzom"

# Tryb interaktywny
python sbert-query-database.py --interactive
```

## ğŸ”§ Opcje zaawansowane

### Kodowanie bazy danych

```bash
# UÅ¼yj innego modelu (polski!)
python sbert-encode-database.py --model sdadas/mmlw-retrieval-roberta-base

# WiÄ™kszy batch size (jeÅ›li masz GPU)
python sbert-encode-database.py --batch-size 64

# WymuÅ› ponowne kodowanie
python sbert-encode-database.py --force

# Pomoc
python sbert-encode-database.py --help
```

### Odpytywanie bazy

```bash
# WiÄ™cej wynikÃ³w
python sbert-query-database.py --query "Twoje zdanie" --top-k 10

# Wszystkie testy naraz
python sbert-query-database.py --all-tests

# Tryb interaktywny (najwygodniejszy!)
python sbert-query-database.py -i
```

## ğŸ“Š PrzykÅ‚adowe wyniki

### Test 1: Zdania wymyÅ›lone (spoza korpusu)

```
ğŸ” Zapytanie: "Jestem bardzo gÅ‚odny i chciaÅ‚bym coÅ› zjeÅ›Ä‡."
Top 5 najbardziej podobnych zdaÅ„:

  1. âœ¨ PodobieÅ„stwo: 0.8234
     ID: 45621
     Zdanie: â€“ ja teÅ¼ nie jem

  2. âœ“ PodobieÅ„stwo: 0.7892
     ID: 12456
     Zdanie: â€” Nie bÃ³j siÄ™ waÄ‡panna, nie zjem ciÄ™!

  3. âœ“ PodobieÅ„stwo: 0.7654
     ID: 78234
     Zdanie: Po chwili otworzyÅ‚ je. RzÄ™dzian siedziaÅ‚ ciÄ…gle pod oknem.
```

### Test 2: Zdania z korpusu (powinny mieÄ‡ similarity â‰ˆ 1.0)

```
ğŸ” Zapytanie (z korpusu, ID=1234):
   "KrÃ³l siedziaÅ‚ na tronie i wydawaÅ‚ rozkazy."
Top 5 wynikÃ³w:

  1. ğŸ¯ PodobieÅ„stwo: 1.0000 â† TO SAMO ZDANIE
     ID: 1234
     Zdanie: KrÃ³l siedziaÅ‚ na tronie i wydawaÅ‚ rozkazy.

  2. â—‹ PodobieÅ„stwo: 0.8567
     ID: 5678
     Zdanie: Monarcha zasiadÅ‚ na swym miejscu.
```

## ğŸ” Modele dla jÄ™zyka polskiego

### DomyÅ›lny (wielojÄ™zyczny)
```python
MODEL_NAME = 'intfloat/multilingual-e5-small'
# Rozmiar: 118M parametrÃ³w
# JÄ™zyki: 100+ (w tym polski)
# JakoÅ›Ä‡ dla polskiego: dobra
```

### Zalecane alternatywy

1. **sdadas/mmlw-retrieval-roberta-base** â­ NAJLEPSZY dla polskiego
   ```bash
   python sbert-encode-database.py --model sdadas/mmlw-retrieval-roberta-base
   ```
   - Trenowany specjalnie na polskim
   - Najlepsza jakoÅ›Ä‡ dla polskich tekstÃ³w
   - Rozmiar: ~500MB

2. **sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2**
   ```bash
   python sbert-encode-database.py --model sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
   ```
   - WielojÄ™zyczny, mniejszy rozmiar
   - Dobry kompromis jakoÅ›Ä‡/szybkoÅ›Ä‡

## ğŸ“ Struktura plikÃ³w

```
M1/embedding/
â”œâ”€â”€ sbert-encode-database.py      # Etap 1: Kodowanie
â”œâ”€â”€ sbert-query-database.py       # Etap 2: Odpytywanie
â”œâ”€â”€ run-sbert.py                  # Oryginalny skrypt (wszystko razem)
â”œâ”€â”€ sbert_sentence_embeddings.npy # Baza embeddingÃ³w (generowana)
â”œâ”€â”€ sbert_sentence_map.json       # Mapa ID â†’ zdanie (generowana)
â””â”€â”€ sbert_database_stats.json     # Statystyki (generowana)
```

## ğŸ¯ Wykonanie zadania 4.3

### Wymagania zadania:
- [x] âœ… ZnaleÅºÄ‡ alternatywÄ™ dla modelu lepiej dostosowanego do polskiego
  - Rekomendacja: `sdadas/mmlw-retrieval-roberta-base`
- [x] âœ… RozdzieliÄ‡ skrypt (kodowanie osobno, odpytywanie osobno)
  - `sbert-encode-database.py` + `sbert-query-database.py`
- [x] âœ… OdpytaÄ‡ o zdania wymyÅ›lone
  - `--test-invented` - 8 rÃ³Å¼nych testowych zapytaÅ„
- [x] âœ… OdpytaÄ‡ o zdania z korpusu treningowego
  - `--test-corpus` - losowe zdania z korpusu, similarity â‰ˆ 1.0

### Testowanie rÃ³Å¼nych modeli:

```bash
# 1. Model domyÅ›lny (wielojÄ™zyczny)
python sbert-encode-database.py
python sbert-query-database.py --all-tests > wyniki_multilingual.txt

# 2. Model polski (NAJLEPSZY!)
python sbert-encode-database.py --model sdadas/mmlw-retrieval-roberta-base --force
python sbert-query-database.py --all-tests > wyniki_polski.txt

# 3. PorÃ³wnaj wyniki
diff wyniki_multilingual.txt wyniki_polski.txt
```

## ğŸ’¡ WskazÃ³wki

### Przyspieszenie kodowania
- UÅ¼yj GPU jeÅ›li dostÄ™pne (automatycznie wykrywane przez sentence-transformers)
- ZwiÄ™ksz `--batch-size` (domyÅ›lnie 32)
- Dla testÃ³w uÅ¼yj mniejszego korpusu: `--corpus PAN_TADEUSZ`

### Tryb interaktywny - najlepszy do eksperymentÃ³w!
```bash
python sbert-query-database.py --interactive
```
Pozwala wpisywaÄ‡ zapytania w czasie rzeczywistym:
```
ğŸ” Zapytanie: wojsko i wojna
ğŸ” Zapytanie: miÅ‚oÅ›Ä‡ i szczÄ™Å›cie
ğŸ” Zapytanie: random  # losowe zdanie z korpusu
ğŸ” Zapytanie: q       # wyjÅ›cie
```

### Debugowanie
- SprawdÅº czy baza istnieje: `ls sbert_*.{npy,json}`
- Zobacz statystyki: `cat sbert_database_stats.json`
- WymuÅ› ponowne kodowanie: `--force`

## ğŸ“ˆ Metryki jakoÅ›ci

### Similarity score
- **0.9 - 1.0** ğŸ”¥ - Bardzo podobne (prawie identyczne)
- **0.8 - 0.9** âœ¨ - Podobne semantycznie
- **0.7 - 0.8** âœ“ - PowiÄ…zane tematycznie
- **< 0.7** â—‹ - SÅ‚abo powiÄ…zane

### Dla zdaÅ„ z korpusu
- **Oczekiwane**: similarity â‰ˆ 1.0 dla tego samego zdania
- **JeÅ›li < 0.95**: Problem z normalizacjÄ… lub modelem

## ğŸ› Troubleshooting

### BÅ‚Ä…d: "Brak pliku sbert_sentence_embeddings.npy"
```bash
# Najpierw zakoduj bazÄ™!
python sbert-encode-database.py
```

### BÅ‚Ä…d: "Model not found"
```bash
# Model zostanie automatycznie pobrany z HuggingFace
# Wymaga poÅ‚Ä…czenia z internetem przy pierwszym uÅ¼yciu
```

### Wolne kodowanie
```bash
# UÅ¼yj mniejszego korpusu do testÃ³w
python sbert-encode-database.py --corpus PAN_TADEUSZ

# Lub wiÄ™kszego batch size (jeÅ›li masz RAM/GPU)
python sbert-encode-database.py --batch-size 64
```

## ğŸ”— Linki

- [Sentence-Transformers Documentation](https://www.sbert.net/)
- [Polski model (sdadas)](https://huggingface.co/sdadas/mmlw-retrieval-roberta-base)
- [Multilingual E5](https://huggingface.co/intfloat/multilingual-e5-small)

---

**Status zadania 4.3**: âœ… UKOÅƒCZONE
