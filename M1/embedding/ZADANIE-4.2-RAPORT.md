# Zadanie 4.2 - Raport z testÃ³w Doc2Vec

## ðŸ“‹ PrzeglÄ…d testÃ³w

### Zakres testowania
- **Korpusy**: 2 (WOLNELEKTURY, ALL)
- **Parametry zmienne**: VECTOR_LENGTH, WINDOW_SIZE, EPOCHS
- **CaÅ‚kowita liczba testÃ³w**: 48 (24 Ã— 2 korpusy)

### Testowane parametry

| Parametr | WartoÅ›ci testowane | Liczba wariantÃ³w |
|----------|-------------------|------------------|
| VECTOR_LENGTH | 20, 50, 100 | 3 |
| WINDOW_SIZE | 5, 10 | 2 |
| EPOCHS | 10, 20, 40, 80 | 4 |
| **Kombinacji na korpus** | - | **24** |

### Parametry staÅ‚e
- **MIN_COUNT**: 4
- **WORKERS**: 4
- **SG_MODE**: 0 (PV-DM - Distributed Memory)
- **dm**: 1

---

## ðŸ† Wyniki testÃ³w

### Ranking globalny (Top 10)

> _Ta sekcja zostanie wypeÅ‚niona po wykonaniu testÃ³w_

```
# Uruchom testy:
python test-doc2vec-params.py

# Wyniki automatycznie zapisane w:
# - doc2vec_training_registry.json
# - Podsumowanie wyÅ›wietlone na koÅ„cu testÃ³w
```

---

## ðŸ“Š Analiza wpÅ‚ywu parametrÃ³w

### 1. VECTOR_LENGTH (Wymiar wektora embeddingu)

**Hipoteza**: WiÄ™ksze wektory = lepsza reprezentacja semantyczna, ale dÅ‚uÅ¼szy trening

| VECTOR_LENGTH | Oczekiwany wpÅ‚yw |
|---------------|------------------|
| 20 | Szybki trening, podstawowa jakoÅ›Ä‡ |
| 50 | Balans jakoÅ›Ä‡/czas |
| 100 | Najlepsza jakoÅ›Ä‡, najdÅ‚uÅ¼szy trening |

**Wyniki**: _Do wypeÅ‚nienia po testach_

---

### 2. WINDOW_SIZE (Rozmiar okna kontekstowego)

**Hipoteza**: WiÄ™ksze okno = lepsze uchwycenie dÅ‚ugodystansowych relacji

| WINDOW_SIZE | Oczekiwany wpÅ‚yw |
|-------------|------------------|
| 5 | Kontekst lokalny, szybki trening |
| 10 | Szerszy kontekst, lepsza semantyka |

**Wyniki**: _Do wypeÅ‚nienia po testach_

---

### 3. EPOCHS (Liczba epok treningu)

**Hipoteza**: WiÄ™cej epok = lepsze embeddingi, ale wiÄ™kszy koszt czasowy

| EPOCHS | Oczekiwany wpÅ‚yw |
|--------|------------------|
| 10 | Szybki baseline |
| 20 | Standardowy trening |
| 40 | Lepsze embeddingi |
| 80 | Maksymalna jakoÅ›Ä‡ (ryzyko overfittingu) |

**Wyniki**: _Do wypeÅ‚nienia po testach_

---

### 4. CORPUS SIZE (Rozmiar korpusu)

**PorÃ³wnanie korpusÃ³w**:

| Korpus | PrzybliÅ¼ony rozmiar | Oczekiwany wpÅ‚yw |
|--------|---------------------|------------------|
| WOLNELEKTURY | ~35 plikÃ³w, tysiÄ…ce zdaÅ„ | Dobra jakoÅ›Ä‡, szybki trening |
| ALL | ~50+ plikÃ³w, dziesiÄ…tki tysiÄ™cy zdaÅ„ | Najlepsza jakoÅ›Ä‡, dÅ‚ugi trening |

**Wyniki**: _Do wypeÅ‚nienia po testach_

---

## ðŸŽ¯ Kluczowe wnioski

> _Ta sekcja zostanie wypeÅ‚niona automatycznie po uruchomieniu testÃ³w_

### Najlepsze parametry
- **Korpus**: ?
- **VECTOR_LENGTH**: ?
- **WINDOW_SIZE**: ?
- **EPOCHS**: ?
- **JakoÅ›Ä‡**: ?
- **Czas treningu**: ?

### WpÅ‚yw na jakoÅ›Ä‡ embeddingu
1. **VECTOR_LENGTH**: ?
2. **WINDOW_SIZE**: ?
3. **EPOCHS**: ?
4. **Rozmiar korpusu**: ?

### Trade-off jakoÅ›Ä‡ vs. czas
- **Najszybsza konfiguracja**: ?
- **Najlepsza konfiguracja**: ?
- **Rekomendacja**: ?

---

## ðŸ“ Pliki wyjÅ›ciowe

Po uruchomieniu testÃ³w wygenerowane zostanÄ…:

1. **doc2vec_training_registry.json**
   - PeÅ‚ny rejestr wszystkich 48 treningÃ³w
   - Parametry, metryki, czasy dla kaÅ¼dego testu

2. **doc2vec_model_test.model**
   - Model z ostatniego testu
   - Format: gensim Doc2Vec

3. **doc2vec_model_sentence_map_test.json**
   - Mapa ID â†’ oryginalne zdania
   - Format: JSON array

---

## ðŸ” Jak przeglÄ…daÄ‡ wyniki

### 1. PrzeglÄ…danie rejestru
```bash
# Wszystkie treningi
python view-training-registry.py

# Ranking jakoÅ›ci
python view-training-registry.py --best

# Analiza parametrÃ³w
python view-training-registry.py --compare
```

### 2. BezpoÅ›rednia analiza JSON
```bash
# Windows PowerShell
Get-Content doc2vec_training_registry.json | ConvertFrom-Json | Format-List

# WyciÄ…gnij tylko jakoÅ›Ä‡
(Get-Content doc2vec_training_registry.json | ConvertFrom-Json).quality_metrics.avg_top1_similarity
```

---

## ðŸ“ˆ Metodyka oceny jakoÅ›ci

### Metryka: `avg_top1_similarity`

Dla kaÅ¼dego testowego zapytania:
1. Tokenizacja zdania
2. Wygenerowanie wektora (inference)
3. Znalezienie najbardziej podobnego zdania z korpusu
4. Zmierzenie podobieÅ„stwa cosinusowego

**Finalna metryka**: Åšrednie podobieÅ„stwo top-1 wyniku ze wszystkich zapytaÅ„

### Testowe zapytania
```python
test_queries = [
    "Jestem gÅ‚odny i bardzo chÄ™tnie zjadÅ‚bym coÅ›.",
    "KrÃ³l siedziaÅ‚ na tronie.",
    "Szlachta polska byÅ‚a dumna ze swoich tradycji.",
    "Wojsko maszerowaÅ‚o przez las.",
    "MiÅ‚oÅ›Ä‡ jest najwaÅ¼niejsza w Å¼yciu."
]
```

### Kategorie jakoÅ›ci
- **excellent**: > 0.8
- **good**: 0.6 - 0.8
- **fair**: 0.4 - 0.6
- **poor**: < 0.4

---

## â±ï¸ Szacowany czas wykonania

### Korpus WOLNELEKTURY (24 testy)
- **EPOCHS=10**: ~0.5-1 min/test
- **EPOCHS=20**: ~1-2 min/test
- **EPOCHS=40**: ~2-4 min/test
- **EPOCHS=80**: ~4-8 min/test
- **Razem**: ~30-60 minut

### Korpus ALL (24 testy)
- **EPOCHS=10**: ~1-2 min/test
- **EPOCHS=20**: ~2-4 min/test
- **EPOCHS=40**: ~4-8 min/test
- **EPOCHS=80**: ~8-16 min/test
- **Razem**: ~60-120 minut

### **CaÅ‚kowity czas**: 90-180 minut (1.5-3 godziny)

---

## ðŸš€ Uruchomienie testÃ³w

```bash
# PrzejdÅº do katalogu
cd C:\djc\dj-course\M1\embedding

# Uruchom testy (uwaga: dÅ‚ugi proces!)
python test-doc2vec-params.py

# Wyniki zapisywane na bieÅ¼Ä…co do rejestru
# W razie przerwania: wyniki juÅ¼ wykonanych testÃ³w sÄ… zachowane
```

---

## ðŸ“ Dodatkowe notatki

### Tokenizer
- **UÅ¼yty**: `bielik-v3-tokenizer.json`
- **Uzasadnienie**: Najlepsze wyniki w testach zadania 3

### Uwagi techniczne
- Wszystkie testy uÅ¼ywajÄ… PV-DM (Distributed Memory)
- Workers=4 dla rÃ³wnolegÅ‚ego przetwarzania
- MIN_COUNT=4 aby filtrowaÄ‡ rzadkie tokeny

---

## âœ… Status zadania

- [x] Implementacja systemu rejestru treningÃ³w
- [x] Funkcja oceny jakoÅ›ci embeddingu
- [x] Skrypt testowy 48 kombinacji
- [x] Skrypt przeglÄ…dania wynikÃ³w
- [ ] Uruchomienie testÃ³w _(oczekuje na wykonanie)_
- [ ] Analiza wynikÃ³w _(po testach)_
- [ ] Wnioski koÅ„cowe _(po testach)_

---

**Data utworzenia**: 2025-11-21  
**Autor**: Zadanie 4.2 - Doc2Vec Paragraph Embeddings  
**Pliki**: `run-doc2vec.py`, `test-doc2vec-params.py`, `view-training-registry.py`
