ENGINE=GEMINI
GEMINI_API_KEY="ðŸ¥²-SIEMANKO-TU-API-KEY-ðŸ¥²"
MODEL_NAME="gemini-2.5-flash"

# ENGINE=LLAMA_CPP
# MODEL_NAME=llama-3.1-8b-instruct
# LLAMA_MODEL_PATH=/TWOJA_SCIEZKA_DO_MODELU/llama.cpp/NAZWA_MODELU.gguf
# LLAMA_GPU_LAYERS=1
# LLAMA_CONTEXT_SIZE=2048

# Ollama REST Client (using requests library and REST API directly)
# ENGINE=OLLAMA_REST
# MODEL_NAME=llama3.1:8b-instruct-q4_K_M
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_TIMEOUT=120

# Ollama Python SDK Client (using ollama-python library as an API wrapper)
# ENGINE=OLLAMA_PYTHON
# MODEL_NAME=llama3.1:8b-instruct-q8_0
# OLLAMA_HOST=http://localhost:11434
# OLLAMA_TIMEOUT=120.0
